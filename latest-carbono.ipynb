{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import FileLink, display\nimport torch.nn as torch_nn\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport os, subprocess, time, json, torch\nimport struct\n\ndef download(download_file_name):\n    os.chdir(f\"/kaggle/working/\")\n    name = f\"{download_file_name}.uai\"\n    display(FileLink(f'{name}'))\n\nclass carbono:\n    def __init__(self, debug=True):\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.layers = []\n        self.model = None\n        self.debug = debug\n        self.labels = None\n        self.details = {}\n\n    def save_pytorch(self, filename='model'):\n        filename = filename + '.pt'\n        \"\"\"Save model in PyTorch format\"\"\"\n        torch.save(self.model.state_dict(), filename)\n    \n    def load_pytorch(self, filename='model.pt'):\n        \"\"\"Load model from PyTorch format\"\"\"\n        if self.model is None:\n            raise ValueError(\"Model architecture must be defined before loading weights\")\n        self.model.load_state_dict(torch.load(filename))\n    \n    def layer(self, input_size, output_size, activation='tanh'):\n        \"\"\"Add a layer to the network, similar to carbono.js\"\"\"\n        self.layers.append({\n            'input_size': input_size,\n            'output_size': output_size,\n            'activation': activation\n        })\n\n        # Check if layers are compatible\n        if len(self.layers) > 1:\n            prev_layer = self.layers[-2]\n            if prev_layer['output_size'] != input_size:\n                raise ValueError(f\"Layer input size {input_size} doesn't match previous layer output size {prev_layer['output_size']}\")\n\n        # Build/rebuild model when layer is added\n        self._build_model()\n        \n        if self.debug:\n            print(f\"Added layer: {input_size} â†’ {output_size} with {activation} activation\")\n\n    def _build_model(self):\n        \"\"\"Build PyTorch model from layers\"\"\"\n        if not self.layers:\n            return\n    \n        layers = []\n        for i, layer_info in enumerate(self.layers):\n            # Add linear layer\n            layers.append(torch_nn.Linear(layer_info['input_size'], layer_info['output_size']))\n            \n            # Add activation, but skip softmax for the last layer\n            if i < len(self.layers) - 1:  # Only add activation for non-final layers\n                if layer_info['activation'] == 'tanh':\n                    layers.append(torch_nn.Tanh())\n                elif layer_info['activation'] == 'relu':\n                    layers.append(torch_nn.ReLU())\n                elif layer_info['activation'] == 'sigmoid':\n                    layers.append(torch_nn.Sigmoid())\n    \n        self.model = torch_nn.Sequential(*layers).to(self.device)\n\n    def train(self, train_set, options=None):\n        if options is None:\n            options = {}\n    \n        # Default options similar to carbono.js\n        epochs = options.get('epochs', 200)\n        learning_rate = options.get('learningRate', 0.212)\n        print_every_epochs = options.get('printEveryEpochs', 10)\n        early_stop_threshold = options.get('earlyStopThreshold', 1e-6)\n        optimizer_type = options.get('optimizer', 'adam')\n        loss_function = options.get('lossFunction', 'cross-entropy')\n    \n        # Convert data to PyTorch format\n        if isinstance(train_set[0]['output'], str):\n            unique_labels = list(set(item['output'] for item in train_set))\n            self.labels = unique_labels\n            \n            num_classes = len(unique_labels)\n            label_to_idx = {label: i for i, label in enumerate(unique_labels)}\n            \n            x_data = torch.tensor([item['input'] for item in train_set], dtype=torch.float32).to(self.device)\n            # Change this part - use class indices instead of one-hot encoding\n            y_data = torch.tensor([label_to_idx[item['output']] for item in train_set], dtype=torch.long).to(self.device)\n        else:\n            x_data = torch.tensor([item['input'] for item in train_set], dtype=torch.float32).to(self.device)\n            y_data = torch.tensor([item['output'] for item in train_set], dtype=torch.float32).to(self.device)\n    \n        # Create DataLoader\n        dataset = torch.utils.data.TensorDataset(x_data, y_data)\n        train_loader = DataLoader(dataset, batch_size=32, shuffle=True)  # Remove generator parameter\n    \n        # Rest of the training code remains the same\n        if loss_function == 'mse':\n            criterion = torch_nn.MSELoss()\n        elif loss_function == 'cross-entropy':\n            criterion = torch_nn.CrossEntropyLoss()\n    \n        if optimizer_type == 'adam':\n            optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n        else:\n            optimizer = torch.optim.SGD(self.model.parameters(), lr=learning_rate)\n    \n        start_time = time.time()\n    \n        for epoch in range(epochs):\n            total_loss = 0\n            for inputs, targets in train_loader:\n                optimizer.zero_grad()\n                outputs = self.model(inputs)\n                loss = criterion(outputs, targets)\n                loss.backward()\n                optimizer.step()\n                \n                total_loss += loss.item()\n    \n            avg_loss = total_loss / len(train_loader)\n            \n            if (epoch + 1) % print_every_epochs == 0 and self.debug:\n                print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.6f}')\n    \n            if avg_loss < early_stop_threshold:\n                if self.debug:\n                    print(f'Early stopping at epoch {epoch+1} with loss: {avg_loss:.6f}')\n                break\n    \n        training_time = (time.time() - start_time) * 1000\n    \n        total_params = sum(p.numel() for p in self.model.parameters())\n        self.details = {\n            'loss': avg_loss,\n            'parameters': total_params,\n            'training': {\n                'time': training_time,\n                'epochs': epoch + 1,\n                'learningRate': learning_rate\n            },\n            'layers': self.layers\n        }\n        return self.details\n\n    def predict(self, input_data, tags=True):\n        \"\"\"Make predictions similar to carbono.js\"\"\"\n        with torch.no_grad():\n            input_tensor = torch.tensor(input_data, dtype=torch.float32).to(self.device)\n            if len(input_tensor.shape) == 1:\n                input_tensor = input_tensor.unsqueeze(0)\n            \n            output = self.model(input_tensor)\n            predictions = output.cpu().numpy()\n\n            if self.labels and tags:\n                # Return labeled probabilities like carbono.js\n                return [\n                    {\n                        'label': self.labels[i],\n                        'probability': float(prob)\n                    }\n                    for i, prob in enumerate(predictions[0])\n                ]\n            \n            return predictions[0].tolist()\n\n    def save(self, filename='model'):\n        filename = filename + '.uai'\n        \"\"\"Export model in carbono.js format\"\"\"\n        carbono_model = {\n            'weights': [],\n            'biases': [],\n            'layers': self.layers,\n            'labels': self.labels,\n            'details': self.details\n        }\n        \n        current_layer = None\n        for layer in self.model:\n            if isinstance(layer, torch_nn.Linear):\n                weights = layer.weight.detach().cpu().numpy().tolist()\n                biases = layer.bias.detach().cpu().numpy().tolist()\n                carbono_model['weights'].append(weights)\n                carbono_model['biases'].append(biases)\n\n        # Convert weights and biases to binary format\n        weight_bin = b''.join([struct.pack('f', w) for layer in carbono_model['weights'] for row in layer for w in row])\n        bias_bin = b''.join([struct.pack('f', b) for layer in carbono_model['biases'] for b in layer])\n\n        # Prepare metadata\n        metadata = {\n            'layers': self.layers,\n            'details': self.details,\n            'layerInfo': {\n                'weightShapes': [list(map(len, [layer, layer[0]])) for layer in carbono_model['weights']],\n                'biasShapes': [len(layer) for layer in carbono_model['biases']]\n            },\n            'labels': self.labels\n        }\n\n        # Combine metadata and binary data\n        metadata_str = json.dumps(metadata)\n        separator = b'\\n---BINARY_SEPARATOR---\\n'\n        binary_data = metadata_str.encode('utf-8') + separator + weight_bin + bias_bin\n\n        # Save to file\n        with open(filename, 'wb') as f:\n            f.write(binary_data)\n\n    def load(self, filename):\n        \"\"\"Load model from carbono.js format\"\"\"\n        with open(filename, 'rb') as f:\n            data = f.read()\n\n        # Find separator\n        separator = b'\\n---BINARY_SEPARATOR---\\n'\n        sep_index = data.find(separator)\n        if sep_index == -1:\n            raise ValueError(\"Invalid file format\")\n\n        # Extract metadata and binary data\n        metadata_str = data[:sep_index].decode('utf-8')\n        binary_data = data[sep_index + len(separator):]\n\n        # Parse metadata\n        metadata = json.loads(metadata_str)\n        self.layers = metadata['layers']\n        self.details = metadata['details']\n        self.labels = metadata.get('labels', None)\n\n        # Rebuild model\n        self._build_model()\n\n        # Extract weights and biases\n        weight_shapes = metadata['layerInfo']['weightShapes']\n        bias_shapes = metadata['layerInfo']['biasShapes']\n\n        # Reconstruct weights and biases\n        weight_size = sum(shape[0] * shape[1] for shape in weight_shapes)\n        bias_size = sum(shape for shape in bias_shapes)\n\n        weights = struct.unpack('f' * weight_size, binary_data[:weight_size * 4])\n        biases = struct.unpack('f' * bias_size, binary_data[weight_size * 4:])\n\n        # Assign weights and biases to model\n        weight_index = 0\n        bias_index = 0\n        layer_index = 0\n        for layer in self.model:\n            if isinstance(layer, torch_nn.Linear):\n                # Assign weights\n                weight_shape = weight_shapes[layer_index]\n                weight_values = weights[weight_index:weight_index + weight_shape[0] * weight_shape[1]]\n                weight_tensor = torch.tensor(weight_values, dtype=torch.float32).reshape(weight_shape[0], weight_shape[1])\n                layer.weight.data = weight_tensor.to(self.device)\n                weight_index += weight_shape[0] * weight_shape[1]\n\n                # Assign biases\n                bias_shape = bias_shapes[layer_index]\n                bias_values = biases[bias_index:bias_index + bias_shape]\n                bias_tensor = torch.tensor(bias_values, dtype=torch.float32)\n                layer.bias.data = bias_tensor.to(self.device)\n                bias_index += bias_shape\n\n                layer_index += 1\n\n        if self.debug:\n            print(\"Model loaded successfully!\")\n\n    def info(self, info_updates):\n        \"\"\"Update model metadata\"\"\"\n        if 'info' not in self.details:\n            self.details['info'] = {}\n        self.details['info'].update(info_updates)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T17:09:53.100099Z","iopub.execute_input":"2025-01-06T17:09:53.100549Z","iopub.status.idle":"2025-01-06T17:09:57.276359Z","shell.execute_reply.started":"2025-01-06T17:09:53.100515Z","shell.execute_reply":"2025-01-06T17:09:57.275010Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Example usage\ntrain_set = [\n    {'input': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'output': 'ðŸ˜€'},  # Smiling Face\n    {'input': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'output': 'ðŸ˜Š'},  # Smiling Face with Smiling Eyes\n    {'input': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'output': 'ðŸ˜‚'},  # Face with Tears of Joy\n    {'input': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'output': 'ðŸ˜'},  # Smiling Face with Heart-Eyes\n    {'input': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'output': 'ðŸ˜Ž'},  # Smiling Face with Sunglasses\n    {'input': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'output': 'ðŸ˜¢'},  # Crying Face\n    {'input': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'output': 'ðŸ˜¡'},  # Pouting Face\n    {'input': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'output': 'ðŸ˜´'},  # Sleeping Face\n    {'input': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'output': 'ðŸ¤”'},  # Thinking Face\n    {'input': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'output': 'ðŸ¤¢'},  # Nauseated Face\n]\n\n# Create and train model\nnn = carbono(debug=True)\n\n# Add layers with specified architecture\nnn.layer(10, 512, 'sigmoid')\nnn.layer(512, 1024, 'relu')\nnn.layer(1024, 128, 'relu')\nnn.layer(128, 10, 'softmax')  # Output layer (3 outputs for 3 classes)\n\n# Train the model with adjusted parameters\ntraining_summary = nn.train(train_set, {\n    'epochs': 1000,\n    'learningRate': 0.0002,\n    'printEveryEpochs': 500,\n    'optimizer': 'adam',\n    'lossFunction': 'cross-entropy'\n})\n\n# Export and download model\nmodel_name = \"v6_model\"\nnn.save(model_name)\ndownload(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T17:16:09.840129Z","iopub.execute_input":"2025-01-06T17:16:09.840817Z","iopub.status.idle":"2025-01-06T17:16:17.125186Z","shell.execute_reply.started":"2025-01-06T17:16:09.840782Z","shell.execute_reply":"2025-01-06T17:16:17.123598Z"}},"outputs":[{"name":"stdout","text":"Added layer: 10 â†’ 512 with sigmoid activation\nAdded layer: 512 â†’ 1024 with relu activation\nAdded layer: 1024 â†’ 128 with relu activation\nAdded layer: 128 â†’ 10 with softmax activation\nEpoch [500/1000], Loss: 0.001897\nEpoch [1000/1000], Loss: 0.000306\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/v6_model.uai","text/html":"<a href='v6_model.uai' target='_blank'>v6_model.uai</a><br>"},"metadata":{}}],"execution_count":3}]}