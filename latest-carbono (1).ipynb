{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import FileLink, display\nimport torch.nn as torch_nn\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport os, subprocess, time, json, torch\nimport struct\n\ndef download(download_file_name):\n    os.chdir(f\"/kaggle/working/\")\n    name = f\"{download_file_name}.uai\"\n    display(FileLink(f'{name}'))\n\nclass carbono:\n    def __init__(self, debug=True):\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.layers = []\n        self.model = None\n        self.debug = debug\n        self.labels = None\n        self.details = {}\n\n    def save_pytorch(self, filename='model'):\n        filename = filename + '.pt'\n        \"\"\"Save model in PyTorch format\"\"\"\n        torch.save(self.model.state_dict(), filename)\n    \n    def load_pytorch(self, filename='model.pt'):\n        \"\"\"Load model from PyTorch format\"\"\"\n        if self.model is None:\n            raise ValueError(\"Model architecture must be defined before loading weights\")\n        self.model.load_state_dict(torch.load(filename))\n    \n    def layer(self, input_size, output_size, activation='tanh'):\n        \"\"\"Add a layer to the network, similar to carbono.js\"\"\"\n        self.layers.append({\n            'input_size': input_size,\n            'output_size': output_size,\n            'activation': activation\n        })\n\n        # Check if layers are compatible\n        if len(self.layers) > 1:\n            prev_layer = self.layers[-2]\n            if prev_layer['output_size'] != input_size:\n                raise ValueError(f\"Layer input size {input_size} doesn't match previous layer output size {prev_layer['output_size']}\")\n\n        # Build/rebuild model when layer is added\n        self._build_model()\n        \n        if self.debug:\n            print(f\"Added layer: {input_size} â†’ {output_size} with {activation} activation\")\n\n    def _build_model(self):\n        \"\"\"Build PyTorch model from layers\"\"\"\n        if not self.layers:\n            return\n    \n        layers = []\n        for i, layer_info in enumerate(self.layers):\n            # Add linear layer\n            layers.append(torch_nn.Linear(layer_info['input_size'], layer_info['output_size']))\n            \n            # Add activation, but skip softmax for the last layer\n            if i < len(self.layers) - 1:  # Only add activation for non-final layers\n                if layer_info['activation'] == 'tanh':\n                    layers.append(torch_nn.Tanh())\n                elif layer_info['activation'] == 'relu':\n                    layers.append(torch_nn.ReLU())\n                elif layer_info['activation'] == 'sigmoid':\n                    layers.append(torch_nn.Sigmoid())\n    \n        self.model = torch_nn.Sequential(*layers).to(self.device)\n\n    def train(self, train_set, options=None):\n        if options is None:\n            options = {}\n    \n        # Default options similar to carbono.js\n        epochs = options.get('epochs', 200)\n        learning_rate = options.get('learningRate', 0.212)\n        print_every_epochs = options.get('printEveryEpochs', 10)\n        early_stop_threshold = options.get('earlyStopThreshold', 1e-6)\n        optimizer_type = options.get('optimizer', 'adam')\n        loss_function = options.get('lossFunction', 'cross-entropy')\n    \n        # Convert data to PyTorch format\n        if isinstance(train_set[0]['output'], str):\n            unique_labels = list(set(item['output'] for item in train_set))\n            self.labels = unique_labels\n            \n            num_classes = len(unique_labels)\n            label_to_idx = {label: i for i, label in enumerate(unique_labels)}\n            \n            x_data = torch.tensor([item['input'] for item in train_set], dtype=torch.float32).to(self.device)\n            # Change this part - use class indices instead of one-hot encoding\n            y_data = torch.tensor([label_to_idx[item['output']] for item in train_set], dtype=torch.long).to(self.device)\n        else:\n            x_data = torch.tensor([item['input'] for item in train_set], dtype=torch.float32).to(self.device)\n            y_data = torch.tensor([item['output'] for item in train_set], dtype=torch.float32).to(self.device)\n    \n        # Create DataLoader\n        dataset = torch.utils.data.TensorDataset(x_data, y_data)\n        train_loader = DataLoader(dataset, batch_size=32, shuffle=True)  # Remove generator parameter\n    \n        # Rest of the training code remains the same\n        if loss_function == 'mse':\n            criterion = torch_nn.MSELoss()\n        elif loss_function == 'cross-entropy':\n            criterion = torch_nn.CrossEntropyLoss()\n    \n        if optimizer_type == 'adam':\n            optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n        else:\n            optimizer = torch.optim.SGD(self.model.parameters(), lr=learning_rate)\n    \n        start_time = time.time()\n    \n        for epoch in range(epochs):\n            total_loss = 0\n            for inputs, targets in train_loader:\n                optimizer.zero_grad()\n                outputs = self.model(inputs)\n                loss = criterion(outputs, targets)\n                loss.backward()\n                optimizer.step()\n                \n                total_loss += loss.item()\n    \n            avg_loss = total_loss / len(train_loader)\n            \n            if (epoch + 1) % print_every_epochs == 0 and self.debug:\n                print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.6f}')\n    \n            if avg_loss < early_stop_threshold:\n                if self.debug:\n                    print(f'Early stopping at epoch {epoch+1} with loss: {avg_loss:.6f}')\n                break\n    \n        training_time = (time.time() - start_time) * 1000\n    \n        total_params = sum(p.numel() for p in self.model.parameters())\n        self.details = {\n            'loss': avg_loss,\n            'parameters': total_params,\n            'training': {\n                'time': training_time,\n                'epochs': epoch + 1,\n                'learningRate': learning_rate\n            },\n            'layers': self.layers\n        }\n        return self.details\n\n    async def predict(self, input_data, tags=True):\n        \"\"\"Make predictions with support for URL inputs\"\"\"\n        try:\n            # Preprocess the input if it's a URL or raw data\n            processed_input = await self.preprocess_data(input_data)\n            \n            # Convert to tensor and ensure correct shape\n            with torch.no_grad():\n                input_tensor = torch.tensor(processed_input, dtype=torch.float32).to(self.device)\n                if len(input_tensor.shape) == 1:\n                    input_tensor = input_tensor.unsqueeze(0)\n                \n                output = self.model(input_tensor)\n                \n                # Apply softmax if using classification\n                if self.labels:\n                    probabilities = torch.nn.functional.softmax(output, dim=1)\n                    predictions = probabilities.cpu().numpy()\n                else:\n                    predictions = output.cpu().numpy()\n    \n                if self.labels and tags:\n                    # Return labeled probabilities\n                    return [\n                        {\n                            'label': self.labels[i],\n                            'probability': float(prob)\n                        }\n                        for i, prob in enumerate(predictions[0])\n                    ]\n                \n                return predictions[0].tolist()\n                \n        except Exception as e:\n            if self.debug:\n                print(f\"Error during prediction: {str(e)}\")\n            raise\n\n\n    def save(self, filename='model', useBinary=True):\n        try:\n            print(\"Starting save process...\")\n            if not self.model:\n                raise ValueError(\"No model to save\")\n    \n            # Extract current model state\n            weights = []\n            biases = []\n            for layer in self.model:\n                if isinstance(layer, torch_nn.Linear):\n                    weights.append(layer.weight.detach().cpu().numpy().tolist())\n                    biases.append(layer.bias.detach().cpu().numpy().tolist())\n    \n            print(\"Model state:\", {\n                \"weightLayers\": len(weights),\n                \"biasLayers\": len(biases),\n                \"modelLayers\": len(self.layers)\n            })\n    \n            # Validate weights and biases\n            if not weights or not biases:\n                raise ValueError(\"Weights or biases are empty. Cannot save model.\")\n    \n            # Prepare metadata\n            if 'info' not in self.details:\n                self.details['info'] = {\n                    'name': filename,\n                    'author': '',\n                    'license': 'MIT',\n                    'note': '',\n                    'date': time.strftime('%Y-%m-%dT%H:%M:%SZ')\n                }\n    \n            # Prepare layer info\n            layer_info = {\n                'weightShapes': [[len(layer), len(layer[0])] for layer in weights],\n                'biasShapes': [len(layer) for layer in biases]\n            }\n    \n            # Create metadata object\n            metadata = {\n                'layers': self.layers,\n                'details': self.details,\n                'layerInfo': layer_info\n            }\n            if self.labels:\n                metadata['labels'] = self.labels\n    \n            if not useBinary:\n                print(\"Using JSON mode\")\n                metadata['weights'] = weights\n                metadata['biases'] = biases\n                with open(f\"{filename}.json\", 'w') as f:\n                    json.dump(metadata, f)\n                return True\n    \n            print(\"Using binary compression mode\")\n    \n            # Calculate total buffer sizes\n            total_weights = sum(shape[0] * shape[1] for shape in layer_info['weightShapes'])\n            total_biases = sum(shape for shape in layer_info['biasShapes'])\n    \n            # Convert metadata to bytes and calculate padding\n            metadata_bytes = json.dumps(metadata).encode('utf-8')\n            metadata_padding = (4 - (len(metadata_bytes) % 4)) % 4\n    \n            # Create header with sizes and padding info\n            header = struct.pack('4I',\n                len(metadata_bytes),    # metadata length\n                metadata_padding,       # padding bytes\n                total_weights,          # total weights\n                total_biases           # total biases\n            )\n    \n            print(\"Header values:\", {\n                'metadataLength': len(metadata_bytes),\n                'padding': metadata_padding,\n                'weightLength': total_weights,\n                'biasLength': total_biases\n            })\n    \n            # Calculate total size with padding\n            total_size = (\n                len(header) +                  # header size\n                len(metadata_bytes) +          # metadata size\n                metadata_padding +             # padding\n                (total_weights * 4) +          # weights size (float32)\n                (total_biases * 4)             # biases size (float32)\n            )\n    \n            # Prepare weights and biases as flat arrays\n            weight_data = struct.pack(f'{total_weights}f',\n                *[w for layer in weights for row in layer for w in row])\n            bias_data = struct.pack(f'{total_biases}f',\n                *[b for layer in biases for b in layer])  # Changed 'bias' to 'layer'\n    \n            # Write the full binary file\n            with open(f\"{filename}.uai\", 'wb') as f:\n                f.write(header)\n                f.write(metadata_bytes)\n                f.write(b'\\x00' * metadata_padding)\n                f.write(weight_data)\n                f.write(bias_data)\n    \n            print(\"Binary file created:\", {\n                'size': total_size,\n                'path': f\"{filename}.uai\"\n            })\n    \n            print(\"Save process completed successfully\")\n            return True\n    \n        except Exception as e:\n            print(\"Save process failed:\", str(e))\n            raise\n    \n    def load(self, filename):\n        try:\n            print(\"Starting load process...\")\n    \n            if not os.path.exists(filename):\n                raise FileNotFoundError(f\"File not found: {filename}\")\n    \n            file_extension = os.path.splitext(filename)[1]\n            useBinary = file_extension.lower() == '.uai'\n    \n            if not useBinary:\n                # Handle JSON loading\n                with open(filename, 'r') as f:\n                    data = json.load(f)\n                    self.layers = data['layers']\n                    self.details = data['details']\n                    if 'labels' in data:\n                        self.labels = data['labels']\n                    \n                    self._build_model()\n                    \n                    # Load weights and biases\n                    for i, layer in enumerate(self.model):\n                        if isinstance(layer, torch_nn.Linear):\n                            weight_tensor = torch.tensor(data['weights'][i], dtype=torch.float32)\n                            bias_tensor = torch.tensor(data['biases'][i], dtype=torch.float32)\n                            layer.weight.data = weight_tensor.to(self.device)\n                            layer.bias.data = bias_tensor.to(self.device)\n                    \n                    print(\"JSON model loaded successfully\")\n                    return True\n    \n            # Binary loading\n            with open(filename, 'rb') as f:\n                # Read header (4 uint32 values)\n                header = struct.unpack('4I', f.read(16))\n                metadata_length, metadata_padding, weight_length, bias_length = header\n    \n                print(\"Header values:\", {\n                    'metadataLength': metadata_length,\n                    'padding': metadata_padding,\n                    'weightLength': weight_length,\n                    'biasLength': bias_length\n                })\n    \n                # Validate file size\n                expected_size = (\n                    16 +                    # header size\n                    metadata_length +       # metadata size\n                    metadata_padding +      # padding\n                    (weight_length * 4) +   # weights size\n                    (bias_length * 4)       # biases size\n                )\n                \n                file_size = os.path.getsize(filename)\n                if file_size != expected_size:\n                    raise ValueError(f\"Invalid file size: expected {expected_size}, got {file_size}\")\n    \n                # Read metadata\n                metadata_bytes = f.read(metadata_length)\n                metadata = json.loads(metadata_bytes.decode('utf-8'))\n    \n                # Skip padding\n                f.read(metadata_padding)\n    \n                # Read weights and biases\n                weight_data = f.read(weight_length * 4)\n                bias_data = f.read(bias_length * 4)\n    \n                # Unpack weights and biases\n                weights = struct.unpack(f'{weight_length}f', weight_data)\n                biases = struct.unpack(f'{bias_length}f', bias_data)\n    \n                # Load metadata into model\n                self.layers = metadata['layers']\n                self.details = metadata['details']\n                if 'labels' in metadata:\n                    self.labels = metadata['labels']\n    \n                # Rebuild model architecture\n                self._build_model()\n    \n                # Reshape and assign weights and biases\n                weight_idx = 0\n                bias_idx = 0\n                layer_idx = 0\n    \n                for layer in self.model:\n                    if isinstance(layer, torch_nn.Linear):\n                        weight_shape = metadata['layerInfo']['weightShapes'][layer_idx]\n                        bias_shape = metadata['layerInfo']['biasShapes'][layer_idx]\n    \n                        # Reshape and assign weights\n                        layer_weights = weights[weight_idx:weight_idx + (weight_shape[0] * weight_shape[1])]\n                        weight_tensor = torch.tensor(layer_weights, dtype=torch.float32).reshape(weight_shape[0], weight_shape[1])\n                        layer.weight.data = weight_tensor.to(self.device)\n                        weight_idx += weight_shape[0] * weight_shape[1]\n    \n                        # Reshape and assign biases\n                        layer_biases = biases[bias_idx:bias_idx + bias_shape]\n                        bias_tensor = torch.tensor(layer_biases, dtype=torch.float32)\n                        layer.bias.data = bias_tensor.to(self.device)\n                        bias_idx += bias_shape\n    \n                        layer_idx += 1\n    \n                print(\"Binary model loaded successfully\")\n                return True\n    \n        except Exception as e:\n            print(\"Load process failed:\", str(e))\n            raise\n    \n        \n\n    def info(self, info_updates):\n        \"\"\"Update model metadata\"\"\"\n        if 'info' not in self.details:\n            self.details['info'] = {}\n        self.details['info'].update(info_updates)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-09T03:18:43.880219Z","iopub.execute_input":"2025-01-09T03:18:43.880627Z","iopub.status.idle":"2025-01-09T03:18:43.929671Z","shell.execute_reply.started":"2025-01-09T03:18:43.880598Z","shell.execute_reply":"2025-01-09T03:18:43.928701Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Example usage\ntrain_set = [\n    {'input': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'output': 'ðŸ˜€'},  # Smiling Face\n    {'input': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'output': 'ðŸ˜Š'},  # Smiling Face with Smiling Eyes\n    {'input': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'output': 'ðŸ˜‚'},  # Face with Tears of Joy\n    {'input': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'output': 'ðŸ˜'},  # Smiling Face with Heart-Eyes\n    {'input': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'output': 'ðŸ˜Ž'},  # Smiling Face with Sunglasses\n    {'input': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'output': 'ðŸ˜¢'},  # Crying Face\n    {'input': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'output': 'ðŸ˜¡'},  # Pouting Face\n    {'input': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'output': 'ðŸ˜´'},  # Sleeping Face\n    {'input': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'output': 'ðŸ¤”'},  # Thinking Face\n    {'input': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], 'output': 'ðŸ¤¢'},  # Nauseated Face\n]\n\n# Create and train model\nnn = carbono(debug=True)\n\n# Add layers with specified architecture\nnn.layer(10, 128, 'sigmoid')\nnn.layer(128, 1024, 'relu')\nnn.layer(1024, 128, 'relu')\nnn.layer(128, 10, 'softmax')  # Output layer (3 outputs for 3 classes)\n\n# Train the model with adjusted parameters\ntraining_summary = nn.train(train_set, {\n    'epochs': 100,\n    'learningRate': 0.0002,\n    'printEveryEpochs': 10,\n    'optimizer': 'adam',\n    'lossFunction': 'cross-entropy'\n})\n\n# Export and download model\nmodel_name = \"emoji\"\nnn.save(model_name, True)\ndownload(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T03:18:48.042637Z","iopub.execute_input":"2025-01-09T03:18:48.043002Z","iopub.status.idle":"2025-01-09T03:18:48.483054Z","shell.execute_reply.started":"2025-01-09T03:18:48.042974Z","shell.execute_reply":"2025-01-09T03:18:48.482141Z"}},"outputs":[{"name":"stdout","text":"Added layer: 10 â†’ 128 with sigmoid activation\nAdded layer: 128 â†’ 1024 with relu activation\nAdded layer: 1024 â†’ 128 with relu activation\nAdded layer: 128 â†’ 10 with softmax activation\nEpoch [10/100], Loss: 2.275840\nEpoch [20/100], Loss: 2.247234\nEpoch [30/100], Loss: 2.211915\nEpoch [40/100], Loss: 2.166773\nEpoch [50/100], Loss: 2.108056\nEpoch [60/100], Loss: 2.031236\nEpoch [70/100], Loss: 1.932660\nEpoch [80/100], Loss: 1.810511\nEpoch [90/100], Loss: 1.662430\nEpoch [100/100], Loss: 1.488777\nStarting save process...\nModel state: {'weightLayers': 4, 'biasLayers': 4, 'modelLayers': 4}\nUsing binary compression mode\nHeader values: {'metadataLength': 1075, 'padding': 1, 'weightLength': 264704, 'biasLength': 1290}\nBinary file created: {'size': 1065068, 'path': 'emoji.uai'}\nSave process completed successfully\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/emoji.uai","text/html":"<a href='emoji.uai' target='_blank'>emoji.uai</a><br>"},"metadata":{}}],"execution_count":4}]}